# Wan2GP - CUDA development Docker image with compiler support
# FROM nvidia/cuda:12.4.1-cudnn-devel-ubuntu20.04
FROM nvidia/cuda:12.8.0-devel-ubuntu24.04

# FROM pytorch/pytorch:2.7.1-cuda12.8-cudnn9-runtime

# Set environment variables
ENV DEBIAN_FRONTEND=noninteractive \
    PYTHONUNBUFFERED=1 \
    NVIDIA_VISIBLE_DEVICES=all \
    NVIDIA_DRIVER_CAPABILITIES=compute,utility \
    HF_HOME=/app/ckpts \
    TRANSFORMERS_CACHE=/app/ckpts \
    HF_HUB_CACHE=/app/ckpts \
    CUDA_HOME=/usr/local/cuda \
    PATH=/usr/local/cuda/bin:$PATH \
    LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH \
    PYENV_ROOT=/opt/pyenv \
    PATH=/opt/pyenv/bin:/opt/pyenv/shims:$PATH

# Set working directory
WORKDIR /app

# Install system dependencies required for pyenv and Python compilation
RUN apt-get update && apt-get install -y --no-install-recommends \
    git \
    wget \
    curl \
    build-essential \
    libssl-dev \
    zlib1g-dev \
    libbz2-dev \
    libreadline-dev \
    libsqlite3-dev \
    libncursesw5-dev \
    xz-utils \
    tk-dev \
    libxml2-dev \
    libxmlsec1-dev \
    libffi-dev \
    liblzma-dev \
    libgl1-mesa-dri \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libgomp1 \
    && rm -rf /var/lib/apt/lists/* \
    && apt-get clean

# Install pyenv
RUN git clone https://github.com/pyenv/pyenv.git /opt/pyenv && \
    cd /opt/pyenv && \
    git checkout v2.3.36

# Install Python 3.11.7 using pyenv and ensure environment is properly set
RUN eval "$(pyenv init -)" && \
    pyenv install 3.11.7 && \
    pyenv global 3.11.7 && \
    pyenv rehash

# Ensure Python environment is properly configured
RUN echo 'eval "$(pyenv init -)"' >> /root/.bashrc && \
    echo 'eval "$(pyenv init -)"' >> /root/.profile

# Update PATH to ensure pyenv python is used
ENV PATH="/opt/pyenv/shims:/opt/pyenv/bin:$PATH"

# Verify Python installation and upgrade pip
RUN python --version && \
    python -m pip install --upgrade pip

# Install PyTorch with CUDA 12.4 support
# RUN pip install --no-cache-dir torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124

# Clone Wan2GP repository
RUN git clone --depth 1 https://github.com/deepbeepmeep/Wan2GP.git .

# Install Wan2GP requirements (this should install torch)
RUN python -m pip install --no-cache-dir -r requirements.txt

# Verify torch is available
RUN python -c "import torch; print(f'PyTorch version: {torch.__version__}')"

# Create directory for models (to be mounted as volume) - this is where Wan2GP actually downloads models
RUN mkdir -p /app/ckpts

# Expose port (assuming it might have a web interface or for port forwarding)
EXPOSE 7860

# Create startup script that handles optional SageAttention installation
RUN echo '#!/bin/bash\n\
\n\
# Function to install SageAttention\n\
install_sage_attention() {\n\
    echo "Installing SageAttention with GPU support..."\n\
    \n\
    # Set environment variables for faster compilation\n\
    export TORCH_CUDA_ARCH_LIST="8.9"\n\
    export CUDA_HOME=/usr/local/cuda\n\
    export PATH=/usr/local/cuda/bin:$PATH\n\
    \n\
    # Aggressive parallelization settings\n\
    NPROC=`nproc`\n\
    export NVCC_THREADS=$NPROC\n\
    export MAX_JOBS=$NPROC\n\
    export FORCE_CUDA=1\n\
    export CUDA_VISIBLE_DEVICES=0\n\
    export CUDA_LAUNCH_BLOCKING=0\n\
    \n\
    # Speed up compilation by using all available cores\n\
    export MAKEFLAGS="-j$NPROC"\n\
    export CMAKE_BUILD_PARALLEL_LEVEL=$NPROC\n\
    \n\
    # Compiler optimizations\n\
    export CFLAGS="-O3 -march=native"\n\
    export CXXFLAGS="-O3 -march=native"\n\
    export NVCCFLAGS="-O3 --use_fast_math --threads=$NPROC"\n\
    \n\
    if nvidia-smi > /dev/null 2>&1; then\n\
        echo "GPU detected, proceeding with SageAttention installation"\n\
        echo "Using optimized build settings:"\n\
        echo "   CUDA Architecture: 8.9 Ada Lovelace L4"\n\
        echo "   NVCC Threads: $NPROC"\n\
        echo "   Max Jobs: $NPROC"\n\
        echo "   CPU Cores: $NPROC"\n\
        echo "   Compiler: O3 + march=native + fast_math"\n\
        echo "Installing build dependencies..."\n\
        python -m pip install wheel ninja\n\
        echo "Cloning SageAttention repository..."\n\
        cd /tmp && git clone --depth 1 https://github.com/thu-ml/SageAttention.git\n\
        cd SageAttention\n\
        echo "Building and installing SageAttention - this may take a few minutes..."\n\
        python -m pip install --no-build-isolation -e . -v\n\
        cd / && rm -rf /tmp/SageAttention\n\
        echo "SageAttention installed successfully"\n\
    else\n\
        echo "No GPU detected, SageAttention installation may fail"\n\
        echo "Make sure to run with --gpus all"\n\
        exit 1\n\
    fi\n\
}\n\
\n\
# Parse arguments\n\
INSTALL_SAGE=false\n\
NEW_ARGS=()\n\
\n\
for arg in "$@"; do\n\
    case $arg in\n\
        --sage-attention)\n\
            INSTALL_SAGE=true\n\
            ;;\n\
        *)\n\
            NEW_ARGS+=("$arg")\n\
            ;;\n\
    esac\n\
done\n\
\n\
echo "Starting Wan2GP container..."\n\
\n\
# Install SageAttention if requested\n\
if [ "$INSTALL_SAGE" = true ]; then\n\
    if ! python -c "import sageattention" 2>/dev/null; then\n\
        install_sage_attention\n\
    else\n\
        echo "SageAttention already installed"\n\
    fi\n\
fi\n\
\n\
echo "Starting application with command: ${NEW_ARGS[@]}"\n\
cd /app\n\
exec "${NEW_ARGS[@]}"\n' > /usr/local/bin/startup.sh && \
    chmod +x /usr/local/bin/startup.sh

# Set startup script as entrypoint
ENTRYPOINT ["/usr/local/bin/startup.sh"]

# Default command to run Wan2GP text-to-video
CMD ["python", "wgp.py", "--i2v"]
