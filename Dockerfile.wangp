# Wan2GP - Simple CUDA-capable Docker image
FROM pytorch/pytorch:2.6.0-cuda12.4-cudnn9-runtime

# Set environment variables
ENV DEBIAN_FRONTEND=noninteractive \
    PYTHONUNBUFFERED=1 \
    NVIDIA_VISIBLE_DEVICES=all \
    NVIDIA_DRIVER_CAPABILITIES=compute,utility \
    HF_HOME=/app/ckpts \
    TRANSFORMERS_CACHE=/app/ckpts \
    HF_HUB_CACHE=/app/ckpts \
    CUDA_HOME=/usr/local/cuda \
    PATH=/usr/local/cuda/bin:$PATH

# Set working directory
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    git \
    wget \
    curl \
    libgl1-mesa-glx \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libgomp1 \
    build-essential \
    && rm -rf /var/lib/apt/lists/* \
    && apt-get clean

# Install PyTorch with CUDA 12.4 as specified in Wan2GP instructions
RUN pip install --no-cache-dir torch==2.6.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/test/cu124

# Clone Wan2GP repository
RUN git clone --depth 1 https://github.com/deepbeepmeep/Wan2GP.git .

# Install Wan2GP requirements
RUN pip install --no-cache-dir -r requirements.txt

# Clone and install SageAttention2
# RUN git clone https://github.com/thu-ml/SageAttention.git /tmp/SageAttention && \
#     cd /tmp/SageAttention && \
#     pip install -e . && \
#     rm -rf /tmp/SageAttention

# Create directory for models (to be mounted as volume) - this is where Wan2GP actually downloads models
RUN mkdir -p /app/ckpts

# Expose port (assuming it might have a web interface or for port forwarding)
EXPOSE 7860

# Default command to run Wan2GP text-to-video
CMD ["python", "wgp.py", "--i2v"]
