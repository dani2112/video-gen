# FramePack - Simple CUDA-capable Docker image
FROM pytorch/pytorch:2.7.1-cuda12.8-cudnn9-runtime

# Set environment variables
ENV DEBIAN_FRONTEND=noninteractive \
    PYTHONUNBUFFERED=1 \
    NVIDIA_VISIBLE_DEVICES=all \
    NVIDIA_DRIVER_CAPABILITIES=compute,utility \
    HF_HOME=/app/models \
    TRANSFORMERS_CACHE=/app/models/transformers \
    HF_HUB_CACHE=/app/models/hub \
    HF_HUB_OFFLINE=1

# Set working directory
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    git \
    wget \
    curl \
    libgl1-mesa-glx \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libgomp1 \
    && rm -rf /var/lib/apt/lists/* \
    && apt-get clean

# Install PyTorch with CUDA 12.6 as recommended in tutorial
RUN pip install --no-cache-dir torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124

# Clone FramePack repository
RUN git clone --depth 1 https://github.com/dani2112/FramePack.git .

# Install FramePack requirements
RUN pip install --no-cache-dir -r requirements.txt

RUN pip install sageattention==1.0.6

# Copy and run the diffusers patching script for offline mode
RUN echo "Patching diffusers for offline mode"
COPY patch_diffusers_offline.py /tmp/patch_diffusers_offline.py
RUN python /tmp/patch_diffusers_offline.py && rm /tmp/patch_diffusers_offline.py

# Create directory for models (to be mounted as volume)
RUN mkdir -p /app/models/transformers /app/models/hub

# Expose port for Gradio interface
EXPOSE 7860

# Default command to run FramePack demo
CMD ["python", "demo_gradio_f1.py", "--server", "0.0.0.0"]
